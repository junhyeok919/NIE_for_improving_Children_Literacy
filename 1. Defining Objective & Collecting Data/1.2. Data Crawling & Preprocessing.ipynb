{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa6cd8e-461c-4c3d-8deb-f79fe3d335e6",
   "metadata": {},
   "source": [
    "## ğŸ”–ëª©ì°¨\n",
    "- [1. Selenium ê¸°ë°˜ ë°ì´í„° í¬ë¡¤ë§](#1.-Selenium-ê¸°ë°˜-ë°ì´í„°-í¬ë¡¤ë§)\n",
    "  - [í¬ë¡¤ë§ ìˆ˜í–‰](#í¬ë¡¤ë§-ìˆ˜í–‰)\n",
    "- [2. ë°ì´í„°ì…‹ ì·¨í•©](#2.-ë°ì´í„°ì…‹-ì·¨í•©)\n",
    "  - [ë°ì´í„° ë³‘í•©](#ë°ì´í„°-ë³‘í•©)\n",
    "  - [ëˆ„ë½ í–‰ í™•ì¸](#ëˆ„ë½-í–‰-í™•ì¸)\n",
    "- [3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬](#3.-í…ìŠ¤íŠ¸-ì „ì²˜ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81cbc6",
   "metadata": {},
   "source": [
    "# 1. Selenium ê¸°ë°˜ ë°ì´í„° í¬ë¡¤ë§\n",
    "- BigkindsCrawler í´ë˜ìŠ¤ & í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ ì›¹ í¬ë¡¤ë§ ì‘ì—…ì„ ìë™í™”í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ad551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "class BigkindsCrawler:\n",
    "    def __init__(self, path, year):\n",
    "        self.df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "        self.year = year\n",
    "        # ê° ì›” ë³„ ë‚ ì§œ ìˆ˜ (Hard-coded) & ê° ì›”\n",
    "        self.months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "        self.days = [\"31\", \"28\", \"31\", \"30\", \"31\", \"30\", \"31\", \"31\", \"30\", \"31\", \"30\", \"31\"]\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.crawled_df = pd.DataFrame(columns=[\"ì¼ì\", \"ì–¸ë¡ ì‚¬\", \"ì œëª©\", \"URL\", \"ë³¸ë¬¸\"])\n",
    "\n",
    "    # set the WebDriver options\n",
    "    def set_driver_options(self):\n",
    "        self.options.add_argument('--window-size=1920,1080')\n",
    "        self.options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        # set User-Agent for preventing access blocked\n",
    "        self.options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)\" +\n",
    "                                  \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\")\n",
    "        # prevent webdriver from closing immediately\n",
    "        self.options.add_experimental_option(\"detach\", True)\n",
    "        # í¬ë¡¬ ë¸Œë¼ìš°ì €ê°€ ì§ì ‘ì ìœ¼ë¡œ ì—´ë¦¬ì§€ ì•Šë„ë¡ ì„¤ì •\n",
    "        self.options.add_argument('--headless')\n",
    "        # ë¶ˆí•„ìš”í•œ ì´ë¯¸ì§€ ë¡œë”© ì—†ì•° (ì‹œê°„ ë‹¨ì¶•)\n",
    "        self.options.add_argument('--disable-logging')\n",
    "        self.options.add_argument('--disable-images')\n",
    "\n",
    "    # csv íŒŒì¼ í•„ìš”: publisher, keywordë¥¼ csvë¡œ ë¨¹ì„\n",
    "    # category: í†µí•© ë¶„ë¥˜ (li: ì •ì¹˜=1, ê²½ì œ=2, ì‚¬íšŒ=3, êµ­ì œ=5)\n",
    "    def executor(self, publisher, m, category, keyword):\n",
    "        res = []\n",
    "\n",
    "        start_day = self.year + \"-\" + self.months[m] + \"-\" + \"01\"\n",
    "        end_day = self.year + \"-\" + self.months[m] + \"-\" + self.days[m]\n",
    "\n",
    "        # webdriver ìƒì„±\n",
    "        driver = webdriver.Chrome(options=self.options)\n",
    "        driver.get(\"https://www.bigkinds.or.kr/v2/news/index.do\")\n",
    "\n",
    "        # ì–¸ë¡ ì‚¬ í´ë¦­\n",
    "        pub = self.transform_publisher(publisher)\n",
    "        driver.find_element(By.XPATH, f\"//*[@id='category_provider_list']/li[{pub}]/span/label\").click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # ê¸°ê°„ í´ë¦­ (ë°°ë„ˆ)\n",
    "        driver.find_element(By.XPATH, \"//*[@id='collapse-step-1-body']/div[3]/div/div[1]/div[1]/a\").click()\n",
    "        # ê¸°ê°„ í´ë¦­ (1ê°œì›”)\n",
    "        driver.find_element(By.XPATH, \"//*[@id='srch-tab1']/div/div[1]/span[3]/label\").click()\n",
    "\n",
    "        # ì‹œì‘ ë‚ ì§œ í´ë¦­\n",
    "        driver.find_element(By.XPATH, \"//*[@id='srch-tab1']/div/div[2]/div/div[1]/img\").click()\n",
    "        start = driver.find_element(By.XPATH, \"//*[@id='search-begin-date']\")\n",
    "        start.send_keys(Keys.CONTROL, 'a')\n",
    "        start.send_keys(start_day)\n",
    "\n",
    "        # ì¢…ë£Œ ë‚ ì§œ í´ë¦­\n",
    "        driver.find_element(By.XPATH, \"//*[@id='srch-tab1']/div/div[2]/div/div[3]/img\").click()\n",
    "        end = driver.find_element(By.XPATH, \"//*[@id='search-end-date']\")\n",
    "        end.send_keys(Keys.CONTROL, 'a')\n",
    "        end.send_keys(end_day)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # í†µí•© ë¶„ë¥˜ í´ë¦­ (ë°°ë„ˆ)\n",
    "        # ê·¸ëƒ¥ í´ë¦­í•˜ë©´ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ ìˆì–´ì„œ webdriver ê¸°ë‹¤ë¦¼\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//*[@id='collapse-step-1-body']/div[3]/div/div[2]/div[1]/a\"))\n",
    "        )\n",
    "        element.click()\n",
    "\n",
    "        # í†µí•© ë¶„ë¥˜ (li: ì •ì¹˜=1, ê²½ì œ=2, ì‚¬íšŒ=3, êµ­ì œ=5)\n",
    "        driver.find_element(By.XPATH, f\"//*[@id='srch-tab3']/ul/li[{category}]/div/span[4]\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # í‚¤ì›Œë“œ ì…ë ¥: ì˜¤ë¥˜ ë‚˜ì§€ ì•Šê²Œ í•œ ê¸€ìì”© ì…ë ¥í•¨\n",
    "        keyword_input = driver.find_element(By.XPATH, \"//*[@id='total-search-key']\")\n",
    "        for k in keyword:\n",
    "            keyword_input.send_keys(k)\n",
    "            time.sleep(0.2)\n",
    "        keyword_input.send_keys(Keys.RETURN)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # ì •í™•ë„ìˆœ\n",
    "        driver.find_element(By.XPATH, \"//*[@id='select1']/option[2]\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            # ë§¨ ìœ„ì˜ ê¸°ì‚¬ í´ë¦­\n",
    "            driver.find_element(By.XPATH, \"//*[@id='news-results']/div[1]/div/div[2]\").click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            # \"ì¼ì\", \"ì–¸ë¡ ì‚¬\", \"ì œëª©\", \"URL\", \"ë³¸ë¬¸\"\n",
    "            try:\n",
    "                date = driver.find_element(By.XPATH,\n",
    "                                           \"//*[@id='news-detail-modal']/div/div/div[1]/div/div[1]/div[1]/ul/li[1]\").text\n",
    "            except NoSuchElementException:\n",
    "                date = \"N/A\"\n",
    "            \n",
    "            title = driver.find_element(By.XPATH, \"//*[@id='news-detail-modal']/div/div/div[1]/div/div[1]/h1\").text\n",
    "\n",
    "            # URL ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "            href_button = driver.find_element(By.XPATH,\n",
    "                                              \"//*[@id='news-detail-modal']/div/div/div[1]/div/div[1]/div[2]/div[1]/button[1]\")\n",
    "\n",
    "            if href_button.text == \"ê¸°ì‚¬ì›ë¬¸\":\n",
    "                href = href_button.get_attribute(\"onclick\")\n",
    "\n",
    "                # ?ê°€ í¬í•¨ë˜ì—ˆì„ ê²½ìš°, ì¿¼ë¦¬ ë¬¸ìì—´ì´ë¯€ë¡œ ë’¤ì˜ ë¬¸ìì—´ì€ ì‚­ì œ\n",
    "                try:\n",
    "                    url = re.search(r'https?://[^?]+', href).group()\n",
    "                except AttributeError:\n",
    "                    # URLì´ ë§¤ì¹˜ë˜ì§€ ì•ŠëŠ” ê²½ìš°, ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ í†µí•´ http ì´í›„ì˜ ë¬¸ìì—´ë§Œ ì €ì¥\n",
    "                    url = re.search(r'https?://+', href).group()\n",
    "            else:\n",
    "                url = \"N/A\"\n",
    "\n",
    "            paper = driver.find_element(By.XPATH, \"//*[@id='news-detail-modal']/div/div/div[1]/div/div[2]\")\n",
    "            main_text = paper.text\n",
    "        except NoSuchElementException:\n",
    "            date = \"N/A\"\n",
    "            publisher = \"N/A\"\n",
    "            title = \"N/A\"\n",
    "            url = \"N/A\"\n",
    "            main_text = \"N/A\"\n",
    "\n",
    "        res.append(date)\n",
    "        res.append(publisher)\n",
    "        res.append(title)\n",
    "        res.append(url)\n",
    "        res.append(main_text)\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        print(res)\n",
    "        return res\n",
    "\n",
    "    # ì›” ë‹¨ìœ„ë³„ë¡œ í¬ë¡¤ë§\n",
    "    def crawling(self, MONTH):\n",
    "        s_index = (MONTH - 1) * 16\n",
    "        size = 16\n",
    "        publishers = self.df.loc[s_index:s_index + size, \"ì–¸ë¡ ì‚¬\"]\n",
    "\n",
    "        categories = self.df.loc[s_index:s_index + size, \"ì¹´í…Œê³ ë¦¬\"]\n",
    "\n",
    "        total_time = 0\n",
    "\n",
    "        for i in range(s_index, s_index + size):\n",
    "            rank_str = self.df.loc[i, \"top-10 í‚¤ì›Œë“œ\"]\n",
    "            rank_str = rank_str.replace(\"'\", '\"')\n",
    "\n",
    "            # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            data_list = json.loads(rank_str)\n",
    "            data_list = data_list[:5]\n",
    "\n",
    "            keywords = [item['name'] for item in data_list]\n",
    "\n",
    "            publisher = publishers[i]\n",
    "            category = categories[i] // 1000000\n",
    "\n",
    "            # ë³€ìˆ˜ ì²´í¬ìš©\n",
    "            print(f\"CSV í–‰ = {i}\")\n",
    "            print(f\"ì–¸ë¡ ì‚¬ = {publisher}\")\n",
    "            print(f\"ì¹´í…Œê³ ë¦¬ = {category}\")\n",
    "\n",
    "            for j, keyword in enumerate(keywords):\n",
    "                s = time.time()\n",
    "                print(\n",
    "                    f\"{'>>>>>  * Process: ' + str(MONTH) + 'th month ' + str(i * 5 + j + 1) + 'th/' + '960th *  <<<<<':^50}\")\n",
    "                self.crawled_df.loc[i * 5 + j, :] = self.executor(publisher, MONTH - 1, category, keyword)\n",
    "                e = time.time()\n",
    "                total_time += round(e - s, 2)\n",
    "                print(f\"ëˆ„ì  ì†Œìš” ì‹œê°„: {total_time:.2f}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "    def transform_publisher(self, p):\n",
    "        pub = 0\n",
    "        if p == \"ê²½í–¥ì‹ ë¬¸\":\n",
    "            pub = 1\n",
    "        elif p == \"ë™ì•„ì¼ë³´\":\n",
    "            pub = 4\n",
    "        elif p == \"ì¡°ì„ ì¼ë³´\":\n",
    "            pub = 8\n",
    "        elif p == \"ì¤‘ì•™ì¼ë³´\":\n",
    "            pub = 9\n",
    "        elif p == \"í•œê²¨ë ˆ\":\n",
    "            pub = 10\n",
    "\n",
    "        return pub\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.crawled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954b195",
   "metadata": {},
   "source": [
    "## í¬ë¡¤ë§ ìˆ˜í–‰\n",
    "- ì‹¤ì œ í¬ë¡¤ë§ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ\n",
    "- ì—°ë„ë¥¼ ì…ë ¥í•˜ë©´ ì´ 12ë‹¬ì— ëŒ€í•œ ê¸°ì‚¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê°ê° csv íŒŒì¼ë¡œ ì €ì¥í•´ì¤Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0dddc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = \"2014\" #ğŸ‘ˆì—¬ê¸°ì— í¬ë¡¤ë§í•  ì—°ë„ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "crawler_2013 = BigkindsCrawler(f\"topkeywords_{YEAR}.csv\", YEAR)\n",
    "crawler_2013.set_driver_options()  # ì˜µì…˜ ì„¸íŒ…\n",
    "\n",
    "# 1 ~ 12ì›”ê¹Œì§€ í¬ë¡¤ë§í•˜ê³ , ê° ì›” ë³„ë¡œ ë°ì´í„° í”„ë ˆì„ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "for Month in range(1, 13):\n",
    "    crawler_2013.crawling(Month)\n",
    "    dataframe = crawler_2013.get_df()\n",
    "    # ì›”ë³„ë¡œ csv ì¶”ì¶œë„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    dataframe.to_csv(f\"{YEAR}_{Month}.csv\", encoding=\"utf-8-sig\")\n",
    "    print(f\"{YEAR}_{Month}.csv complete! \\n\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_2013.crawled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea7495-ef45-49b3-9f28-9d6d9edec2d9",
   "metadata": {},
   "source": [
    "# 2. ë°ì´í„°ì…‹ ì·¨í•©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8f3ae-9b9a-4e37-b1cd-952afd59e1ed",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë³‘í•©\n",
    "- ì›”ë³„ë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ì„ ì „ë¶€ í•˜ë‚˜ë¡œ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac12bb-ac17-4ecf-ba29-5428aa24f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ì›”ë³„ ë°ì´í„°í”„ë ˆì„ì„ ì €ì¥í•  ê³µê°„\n",
    "dataframes = []\n",
    "\n",
    "# 2013ë…„ë¶€í„° 2022ë…„ê¹Œì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "for year in range(2013, 2023):\n",
    "    for month in range(1, 13):\n",
    "        filename = f\"{year}_{month}.csv\"\n",
    "        df = pd.read_csv(filename, encoding=\"utf-8-sig\")\n",
    "        dataframes.append(df)\n",
    "        \n",
    "\n",
    "# í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ê²°í•©\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2a812-a517-4ece-8180-ba3f91377635",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataframes) # 12ê°œì›” * 9ë…„ì¹˜ = 84 ë§ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a54e9-16da-431a-b1cc-c83069d06a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80364a5-5935-4587-a9d8-f1fb39e6cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[['ì–¸ë¡ ì‚¬','ì œëª©','ë³¸ë¬¸','ì¼ì','URL']] # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¹€\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0d69d-d80f-4ad9-9395-081bf702c752",
   "metadata": {},
   "source": [
    "â¡ï¸1ë…„ì— 960í–‰ * 10ë…„ì¹˜ = 9,600 í–‰ ë§ìŒ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e06be8-47b5-4a83-92ce-434aa335dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ì¹´í…Œê³ ë¦¬' ì»¬ëŸ¼ ë‹¤ì‹œ ì¶”ê°€ (by ì¬ì–¸)\n",
    "combined_df = pd.read_csv(\"9600 ì¹´í…Œê³ ë¦¬.csv\", encoding=\"utf-8-sig\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69034426-e32c-45aa-8aeb-cda75d39efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_politics = combined_df['ì¹´í…Œê³ ë¦¬'].value_counts().get('êµ­ì œ', 0)\n",
    "count_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9562c-69be-4cf2-a7f3-aee791547152",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[['ì–¸ë¡ ì‚¬','ì œëª©','ì¹´í…Œê³ ë¦¬','ë³¸ë¬¸','ì¼ì','URL']]\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7d050-241f-481b-bfc2-53f5a01e07ba",
   "metadata": {},
   "source": [
    "## ëˆ„ë½ í–‰ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805a797-413d-4fcf-af3c-d9b1dec17064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ë³¸ë¬¸' columnì— ëˆ„ë½ëœ ê²½ìš° ìˆëŠ”ì§€ í™•ì¸\n",
    "missing_rows = combined_df[combined_df.iloc[:, 3].isna()]\n",
    "\n",
    "missing_rows = pd.DataFrame(missing_rows)\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3200ee-fba2-4fa2-8f2e-a85ea61b6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087b989-4801-415a-a5a2-04a5961a5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.dropna(subset=['ë³¸ë¬¸'])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d6fc2-7a57-4f6c-9274-bd1dd06c13d9",
   "metadata": {},
   "source": [
    "# 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "- í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë‚œì´ë„ë¥¼ í‰ê°€í•˜ëŠ” ë°ì— ë°©í•´ê°€ ë˜ëŠ” ìš”ì†Œ(íŠ¹ìˆ˜ê¸°í˜¸, í•œì ë° ì¼ë³¸ì–´, ì´ë©”ì¼ ë° ì‚¬ì´íŠ¸ ì£¼ì†Œ, ê°ì¢… ê´„í˜¸)ë¥¼ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487856b6-5f12-4565-9644-d06022ca6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('C:/Users/simon/PythonWorkspace/Psat_Datamining')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f9779-d198-4182-a341-5d9bc6583d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    # textê°€ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # (/br)ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì œê±°\n",
    "    text = text.replace('(/br)', ' ')\n",
    "    # íŠ¹ìˆ˜ ë¬¸ì ì§€ì • í›„ ì œê±°\n",
    "    text = re.sub(r'[â˜â–¶â—†#âŠ™â€»â–³â–½â–¼â–¡â– â—‡â—â˜â—‹]+', ' ', text, flags=re.UNICODE)\n",
    "    text = re.sub(r'ã€ƒ', ' ', text)  \n",
    "    # í•œì ë° ì¼ë³¸ì–´ ì œê±°\n",
    "    text = re.sub(r'[\\p{Script=Hiragana}\\p{Script=Katakana}\\p{Script=Han}]+', ' ', text, flags=re.UNICODE)\n",
    "    # ì´ë©”ì¼ ì£¼ì†Œ ì œê±°\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    # ì‚¬ì´íŠ¸ ì£¼ì†Œ ì œê±°(www. ìœ¼ë¡œ ì‹œì‘í•˜ê³  .krë¡œ ëë‚˜ëŠ” ê²½ìš°)\n",
    "    text = re.sub(r'www\\..+\\.kr', ' ', text)\n",
    "    \n",
    "    # ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë‚´ìš©ì„ ì‚­ì œ (10ê¸€ì ë¯¸ë§Œì¸ ê²½ìš°ëŠ” ì‚­ì œ, 10ê¸€ì ì´ìƒì¸ ê²½ìš°ëŠ” ìœ ì§€)\n",
    "    text = re.sub(r'\\[([^\\]]{1,9})\\]', ' ', text)\n",
    "    text = re.sub(r'\\[([^\\]]{10,})\\]', r'\\1', text)\n",
    "    # \"<...>\"ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë‚´ìš©ì„ ì‚­ì œ\n",
    "    text = re.sub(r'<[^>]*>', ' ', text)\n",
    "    # ì†Œê´„í˜¸ ì•ˆì— ì•„ë¬´ëŸ° ë‚´ìš©ë„ ì—†ìœ¼ë©´ ì‚­ì œ\n",
    "    text = re.sub(r'\\(\\s*\\)', ' ', text)\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ìœ¼ë¡œ spaceê°€ ì—¬ëŸ¬ ë²ˆ ìˆëŠ” ê²½ìš°ë¥¼ ì „ë¶€ ë‹¨ì¼ spaceë¡œ ì •ë¦¬!\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocess_news(df, column_name = 'ë³¸ë¬¸'):\n",
    "    df[column_name] = df[column_name].apply(cleaning_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699685aa-5821-43aa-9498-e3b4935fd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = preprocess_news(combined_df)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1130f-0dbc-406f-b0d6-1c4d5965b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëˆ„ë½ëœ í–‰ ì—†ëŠ”ì§€ ì¬í™•ì¸\n",
    "missing_rows = combined_df[combined_df.iloc[:, 3].isna()]\n",
    "missing_rows = pd.DataFrame(missing_rows)\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fed3e-0c8f-4cfd-8e85-bb9431b7dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ë¡œ ìµœì¢… ì¶”ì¶œ!!\n",
    "combined_df.to_csv(\"~~ë°ì´í„°ì…‹ ì·¨í•©ë³¸~~.csv\", encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
