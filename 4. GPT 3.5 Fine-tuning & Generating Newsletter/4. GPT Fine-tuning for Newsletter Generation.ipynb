{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5b8e29-b3a1-4660-bf49-1c623cc393bc",
   "metadata": {},
   "source": [
    "## 🔖목차\n",
    "- **1. GPT 3.5 turbo 모델에 Fine-tuning 수행**\n",
    "  - Fine-tuning 데이터셋 불러오기\n",
    "  - Fine-tuning용 jsonl 파일 생성\n",
    "  - Fine-tuning 데이터셋을 API 환경에 업로드\n",
    "  - Fine-tuning Job 생성\n",
    "  - Fine-tuning 작업 상태 확인\n",
    "- **2. Fine-tuned 모델로 뉴스레터 생성**\n",
    "  - 예시 데이터셋에 적용\n",
    "  - 실제 뉴스 데이터셋에 적용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1debfb",
   "metadata": {},
   "source": [
    "## **1. GPT 3.5 turbo 모델에 Fine-tuning 수행**\n",
    "- 일관된 형태로 양질의 뉴스레터를 생성하기 위해 해당 작업에 특화된 모델로 미세 조정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41796840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 초기화\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT API 클라이언트 초기화\n",
    "api_key = \"본인의 API key를 입력\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81436b47",
   "metadata": {},
   "source": [
    "### 1.1. Fine-tuning 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning에 사용할 데이터 40건 불러오기\n",
    "data = pd.read_csv('tuning_data_ver3.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009391ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input 데이터 예시 확인\n",
    "print(data.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output 데이터 예시 확인\n",
    "print(data.iloc[0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcedc3b",
   "metadata": {},
   "source": [
    "### 1.2. Fine-tuning용 jsonl 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77516d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝 데이터를 위한 빈 리스트를 생성\n",
    "tuning_data = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "           {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"당신은 초등학생들을 위해 원본 신문기사를 뉴스레터 형태로 바꿔서 작성해주는 기자입니다. 어려운 신문 기사를 뉴스레터 형태로 바꿔서 작성한다면, 학생들이 본문 내용을 더욱 쉽게 이해할 수 있을 것입니다. 아래의 조건들을 바탕으로, [원본 신문기사]를 뉴스레터 형태로 작성해주세요. 조건 1 : 모든 문장에서 학생들에게 친밀감 있는 말투를 사용해주세요. 조건 2 : 적절한 이모지를 사용해주세요. 조건 3 : 결과물은 4개의 Part으로 구성해주세요. 구성은 다음과 같습니다. 1st Part : 간단한 인사와 함께 [원본 신문기사]의 주제에 대해서 소개해주세요. 2nd Part : [원본 신문기사]에 등장하는 단어들 중, [어려운 어휘]에 속하는 단어들을 쉽게 풀어서 설명해주세요. 3rd Part : [원본 신문기사]의 본문을 초등학생이 이해하기 쉬운 말로 풀어서 작성해주세요. 단, 본문의 내용이 지나치게 요약되면 안 됩니다. 본문 내용을 최대한 보존한 상태에서, 어려운 표현들만 쉽게 풀어서 작성해주세요. 4th Part : 본문 내용을 정리하면서 마무리 인사를 해주세요. 조건 4 : 글의 전반적인 구성과 형태를 뉴스레터처럼 구성해주세요.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": '[원본 신문기사] : {}'.format(row[\"Input\"])\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": '[어려운 어휘] : {}'.format(row[\"어려운 어휘\"])\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": row[\"수정본\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    tuning_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2223b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json formatted data to jsonl → fine_tuning_data2 → fine_tuning_data3로 이름 바꿈\n",
    "with open(\"fine_tuning_data3.jsonl\" , encoding= \"utf-8\", mode=\"w\") as file: \n",
    "    for i in tuning_data: \n",
    "        file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ec7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 확인(한 줄씩 빈 행이 나오는 건 정상, 원 데이터에는 빈 행 없음)\n",
    "with open(\"fine_tuning_data3.jsonl\") as f: \n",
    "    for line in f: print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66275d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tuning_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4544aa",
   "metadata": {},
   "source": [
    "### 1.3. Fine-tuning 데이터셋을 API 환경에 업로드\n",
    "- 앞서 만든 \"fine_tuning_data3.jsonl\" 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API keys\n",
    "openai.api_key = api_key\n",
    "\n",
    "# File names is 'processed_data.jsonL\n",
    "with open('fine_tuning_data3.jsonl', 'rb') as file:\n",
    "    response = openai.File.create(\n",
    "        file = file,\n",
    "        purpose = 'fine-tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b018399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드 된 파일 ID 확인\n",
    "file_id = response['id']\n",
    "print(f'File uploaded successfully with ID: {file_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56087e99",
   "metadata": {},
   "source": [
    "### 1.4. Fine-tuning Job 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send fine-tuning request\n",
    "tuning_job = openai.FineTuningJob.create(\n",
    "    training_file = file_id,\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 job ID 확인\n",
    "fine_tuning_job_id = tuning_job['id']\n",
    "print(f\"Fine-tuning job created successfully with ID : {fine_tuning_job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be4b16-c20d-408e-86ab-706653a515bb",
   "metadata": {},
   "source": [
    "### 1.5. Fine-tuning 작업 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea162bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 상태 확인\n",
    "job = openai.FineTuningJob.retrieve(id=fine_tuning_job_id)\n",
    "\n",
    "# 작업 상태 출력 (시간은 좀 걸릴 수도 있음, succeeded가 나오면 완료)\n",
    "print(job['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477db8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning 완료 후 모델 ID 확인\n",
    "fine_tune_status = openai.FineTuningJob.retrieve(fine_tuning_job_id)\n",
    "model_id = fine_tune_status[\"fine_tuned_model\"]\n",
    "\n",
    "print(f\"Created Fine-tuned model with ID : {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83084e",
   "metadata": {},
   "source": [
    "## **2. Fine-tuning 모델 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44ca34-8c76-4f81-a842-7fdc674ae706",
   "metadata": {},
   "source": [
    "### 2.1. 예시 데이터셋에 적용\n",
    "- 실제 뉴스 본문 데이터셋에 적용한 내용은 아래 2.2절 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe49ca-c5ff-4836-a7d7-14a79651aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT API 클라이언트 초기화\n",
    "openai.api_key = \"⭐본인의 API key를 입력\"\n",
    "# Fine-tuned 모델 ID를 입력\n",
    "model_id = '⭐Fine-tuning 완료한 모델의 ID를 입력'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ed8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스레터로 변환할 기사 원본 불러오기 (여기서는 예시 데이터 사용)\n",
    "ex_data = pd.read_csv('ex_data.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ab300",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = ex_data.iloc[0, 0] # '원본 신문 기사'가 담긴 컬럼\n",
    "to_change_words = ex_data.iloc[0, 1] # '설명해야 할 어려운 단어'가 담긴 컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2902f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 프롬프트 설정\n",
    "prompt = [ \n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"당신은 초등학생들을 위해 원본 신문기사를 뉴스레터 형태로 바꿔서 작성해주는 기자입니다. 어려운 신문 기사를 뉴스레터 형태로 바꿔서 작성한다면, 학생들이 본문 내용을 더욱 쉽게 이해할 수 있을 것입니다. 아래의 조건들을 바탕으로, [원본 신문기사]를 뉴스레터 형태로 작성해주세요. 조건 1 : 모든 문장에서 학생들에게 친밀감 있는 말투를 사용해주세요. 조건 2 : 적절한 이모지를 사용해주세요. 조건 3 : 결과물은 4개의 Part으로 구성해주세요. 구성은 다음과 같습니다. 1st Part : 간단한 인사와 함께 [원본 신문기사]의 주제에 대해서 소개해주세요. 2nd Part : [원본 신문기사]에 등장하는 단어들 중, [어려운 어휘]에 속하는 단어들을 쉽게 풀어서 설명해주세요. 3rd Part : [원본 신문기사]의 본문을 초등학생이 이해하기 쉬운 말로 풀어서 작성해주세요. 단, 본문의 내용이 지나치게 요약되면 안 됩니다. 본문 내용을 최대한 보존한 상태에서, 어려운 표현들만 쉽게 풀어서 작성해주세요. 4th Part : 본문 내용을 정리하면서 마무리 인사를 해주세요. 조건 4 : 글의 전반적인 구성과 형태를 뉴스레터처럼 구성해주세요.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": '[원본 신문기사] : {}'.format(article)\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": '[어려운 어휘] : {}'.format(to_change_words)\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ac32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239df8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned GPT 모델에 메시지 보내기\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_id,\n",
    "    messages=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "chat_response = response['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5566363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned GPT의 답변 결과 출력\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb7321-b7d1-45d5-bb05-ca8b01f37987",
   "metadata": {},
   "source": [
    "### 2.2. 실제 뉴스 데이터셋에 적용\n",
    "- 뉴스레터 생성 절차\n",
    "    1. 신문 기사를 입력 받으면 자동으로 어려운 어휘를 산출함\n",
    "    2. 어려운 어휘와 함께 신문 기사를 파인튜닝된 모델에 입력\n",
    "    3. 어린이 맞춤형 뉴스레터로 출력 (총 2,237건 생성 완료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd267b0-3600-4298-acb1-ddb41cd5f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- # 0. 어려운 어휘 산출을 위한 calculate_noun_difficulty 함수 준비\n",
    "\n",
    "# 바른 형태소 분석기 설정\n",
    "import bareunpy\n",
    "from bareunpy import Tagger\n",
    "API_KEY=\"⭐본인의 API key를 입력\"\n",
    "my_tagger = Tagger(API_KEY, 'localhost')\n",
    "\n",
    "# 기타 라이브러리 불러오기\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "\n",
    "# 빈도 수 데이터 불러오기\n",
    "corp_freq = pd.read_csv('~~일상빈도 데이터~~.csv', encoding = 'utf-8-sig') # 일상 빈도 데이터\n",
    "corp_freq.drop(['Unnamed: 0', 'ratio(%)'], inplace = True, axis = 1)\n",
    "mean = np.mean(corp_freq['frequency']) # 평균 이하 형태소는 잘라내기\n",
    "daily_usage = corp_freq[corp_freq['frequency'] >= mean]\n",
    "\n",
    "wave_corp = pd.read_csv('~~물결21 빈도 데이터~~.csv', encoding='utf-8-sig') # 물결 21 빈도 데이터\n",
    "wave_corp.drop(['Unnamed: 0.1', 'Unnamed: 0'], inplace = True, axis = 1)\n",
    "\n",
    "# 불용어 정의\n",
    "stopwords = ['요구', '특파원', '참석자', '희생자', '기자', '지난해', '양국', '갑', '을', '중대형', '승용차', '이듬해', '핸드볼',\n",
    "             '국가', '연합뉴스', '당국', '지난해', '기업', '상승세', '닷새', '누리집', '꼴찌', '사망자', '이날', '대통령', '지역',\n",
    "             '시인', '메시지', '센터', '시', '의료원', '붕괴', '기자실', '보고서', '소폭', '라이벌', '노조', '내년도', '견제', '앵커',\n",
    "             '논설위원', '수락', '리서치', '타임스', '무죄', '뉴시스', '도', '조사', '상당수', '지난달', '마다', '주', '가운데', '개방',\n",
    "            '연평균', '고속버스', '평균', '관계자', '고교', '연면적', '참가자', '당시', '주석', '선수단']\n",
    "\n",
    "# 각 기사 본문의 NF-iDF를 계산하는 함수 정의\n",
    "def calculate_noun_difficulty(input_data, daily_usage, wave_corp, my_tagger, desired_pos_tags=['NNG'], stopwords=None):\n",
    "    start_time = time.time()\n",
    "    score_column = []\n",
    "\n",
    "    for i, line in enumerate(input_data['본문'], start=1):\n",
    "        score_list = []\n",
    "        res = my_tagger.tags([line])\n",
    "\n",
    "        total_usage = 0\n",
    "        filtered_result = [(word, pos) for word, pos in res.pos() if pos in desired_pos_tags]\n",
    "        tokens = [word for word, _ in filtered_result]\n",
    "\n",
    "        for token in tokens:\n",
    "            daily_freq = daily_usage.loc[daily_usage['corpus'] == token, 'frequency'].mean()\n",
    "            wave_freq = wave_corp.loc[wave_corp['단어'] == token, '총 빈도수'].mean()\n",
    "\n",
    "            if np.isnan(daily_freq):\n",
    "                score = wave_freq / 1\n",
    "            else:\n",
    "                score = wave_freq / daily_freq\n",
    "\n",
    "            score_tuple = (token, score)\n",
    "            score_list.append(score_tuple)\n",
    "\n",
    "        score_column.append(score_list)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Score Calculating Processed {i} samples. Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    input_data['점수_tuple'] = score_column\n",
    "\n",
    "    total_word_list = []\n",
    "    for i in range(len(input_data)):\n",
    "        line = input_data.loc[i, '점수_tuple']\n",
    "        word_list = [word for (word, _) in line]\n",
    "        total_word_list.append(word_list)\n",
    "\n",
    "    input_data['counter'] = total_word_list\n",
    "\n",
    "    total_result_list = []\n",
    "    for l in input_data['counter']:\n",
    "        asd = Counter(l)\n",
    "        word_frequency_pairs = list(asd.items())\n",
    "        result_list = []\n",
    "        result_list.extend(word_frequency_pairs)\n",
    "        total_result_list.append(result_list)\n",
    "\n",
    "    input_data['counter'] = total_result_list\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "        list1 = input_data.loc[i, '점수_tuple']\n",
    "        list2 = input_data.loc[i, 'counter']\n",
    "\n",
    "        new_tuple_list = []\n",
    "\n",
    "        for tup1 in list1:\n",
    "            word = tup1[0]\n",
    "            matching_tup2 = next((tup for tup in list2 if tup[0] == word), None)\n",
    "\n",
    "            if matching_tup2 is not None:\n",
    "                new_tuple = (word, matching_tup2[1] * tup1[1])\n",
    "                new_tuple_list.append(new_tuple)\n",
    "\n",
    "        result_list.append(new_tuple_list)\n",
    "\n",
    "    input_data['단어난이도'] = result_list\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "        line = input_data.loc[i, '단어난이도']\n",
    "        line_without_nan = [(word, num) for word, num in line if not pd.isna(num)]\n",
    "        sorted_result = sorted(line_without_nan, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        unique_values = set()\n",
    "        unique_result = [(word, num) for word, num in sorted_result if word not in unique_values and not unique_values.add(word)]\n",
    "\n",
    "        if stopwords:\n",
    "            unique_result = [(word, num) for word, num in unique_result if word not in stopwords]\n",
    "\n",
    "        final_list.append(unique_result)\n",
    "\n",
    "    input_data['단어난이도'] = final_list\n",
    "\n",
    "    num_list = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "        line = input_data.loc[i, '단어난이도']\n",
    "        for (_, num) in line:\n",
    "            num_list.append(num)\n",
    "\n",
    "    top6_list = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "        line = input_data.loc[i, '단어난이도']\n",
    "        lbyl_list = []\n",
    "        for (word, num) in line:\n",
    "            lbyl_list.append(word)\n",
    "            if len(lbyl_list) == 6:\n",
    "                break\n",
    "        top6_list.append(lbyl_list)\n",
    "\n",
    "    input_data['top6'] = top6_list #👈GPT에 전달할 어려운 어휘 Top6\n",
    "\n",
    "    final_result = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "        list1 = input_data.loc[i, '단어난이도']\n",
    "        단어난이도_list = [tup[1] for tup in list1]\n",
    "\n",
    "        단어난이도_sum = sum(단어난이도_list) / len(단어난이도_list)\n",
    "        final_result.append(단어난이도_sum)\n",
    "\n",
    "    input_data['명사난이도 평균 점수'] = final_result #👈기사별 NF-iDF 측정\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Final Score Calculated elapsed time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129c963-103f-43cd-ae56-d6cec0533d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- # 1. 실제 데이터셋에 대해 어려운 어휘 산출\n",
    "\n",
    "# 뉴스레터로 변환할 신문 기사 데이터 로드\n",
    "input_data = pd.read_csv('~~신문기사 원본 데이터셋~~.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "# calculate_noun_difficulty 함수를 사용해 '어려운 어휘 Top6'를 산출\n",
    "result_data = calculate_noun_difficulty(input_data=input_data, \n",
    "                                        daily_usage=daily_usage, \n",
    "                                        wave_corp=wave_corp, \n",
    "                                        my_tagger=my_tagger, \n",
    "                                        stopwords=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581e27e-6d39-4499-873b-716ab4a5d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- # 2. 신문기사 & 어려운 어휘를 Fine-tuned GPT에 전달\n",
    "\n",
    "# 전체 데이터에 대한 gpt_answer 열 추가\n",
    "result_data['gpt_answer'] = ''\n",
    "\n",
    "start_time = time.time()\n",
    "for index, row in result_data.iterrows(): \n",
    "    article = row['본문'] #👈Fine-tuned GPT에게 입력할 '기사 본문'\n",
    "    to_change_words = row['top6'] #👈Fine-tuned GPT에게 입력할 '어려운 어휘'\n",
    "    \n",
    "    to_change_again = []\n",
    "    for word in to_change_words :\n",
    "        to_change_again.append(word)\n",
    "    \n",
    "    to_change_again = ', '.join(to_change_again)\n",
    "\n",
    "    # prompt 정의\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"당신은 초등학생들을 위해 원본 신문기사를 뉴스레터 형태로 바꿔서 작성해주는 기자입니다. 어려운 신문 기사를 뉴스레터 형태로 바꿔서 작성한다면, 학생들이 본문 내용을 더욱 쉽게 이해할 수 있을 것입니다. 아래의 조건들을 바탕으로, [원본 신문기사]를 뉴스레터 형태로 작성해주세요. 조건 1 : 모든 문장에서 학생들에게 친밀감 있는 말투를 사용해주세요. 조건 2 : 적절한 이모지를 사용해주세요. 조건 3 : 결과물은 4개의 Part으로 구성해주세요. 구성은 다음과 같습니다. 1st Part : 간단한 인사와 함께 [원본 신문기사]의 주제에 대해서 소개해주세요. 2nd Part : [원본 신문기사]에 등장하는 단어들 중, [어려운 어휘]에 속하는 단어들을 쉽게 풀어서 설명해주세요. 3rd Part : [원본 신문기사]의 본문을 초등학생이 이해하기 쉬운 말로 풀어서 작성해주세요. 단, 본문의 내용이 지나치게 요약되면 안 됩니다. 본문 내용을 최대한 보존한 상태에서, 어려운 표현들만 쉽게 풀어서 작성해주세요. 4th Part : 본문 내용을 정리하면서 마무리 인사를 해주세요. 조건 4 : 글의 전반적인 구성과 형태를 뉴스레터처럼 구성해주세요.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": '[원본 신문기사] : {}'.format(article)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": '[어려운 어휘] : {}'.format(to_change_again)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Fine-tuned GPT에 쿼리 보내기\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=prompt,\n",
    "        model=model_id,\n",
    "    )\n",
    "\n",
    "    # Fine-tuned GPT의 답변을 받아서 데이터프레임에 추가\n",
    "    result_data.at[index, 'gpt_answer'] = chat_completion.choices[0].message.content\n",
    "    \n",
    "    # 샘플 10개당 시간 측정\n",
    "    if index % 1 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Processed {index}th samples. Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f1098-dfc3-44b7-a145-05bc82f59478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- # 3. 어린이 맞춤형 뉴스레터 2,237건 출력 완료 \n",
    "\n",
    "result_data.head() # 결과 확인\n",
    "result_data.to_csv('~~뉴스레터 생성 완료 데이터셋~~.csv', encoding = 'utf-8-sig', index = False) # CSV 파일로 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
